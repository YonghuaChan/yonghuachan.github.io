<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Async IO in Python]]></title>
    <url>%2F2020%2F01%2F06%2FAsync-IO-in-Python%2F</url>
    <content type="text"><![CDATA[本文将会解释 Python 的异步模块 asyncio 的概念和基本用法。 Async IO 是一种并发编程设计，在 Python 中得到了专门的支持，从 Python 3.4迅速发展到3.7，甚至可能更高。 以下你将会涉及的内容 异步 IO (Asynchronous IO | async IO) : 一种与语言无关的范例(模型) ，其实现跨多种编程语言 async/await: 两个用于定义协同程序的新 Python 关键字 asyncio: Python 包，它为运行和管理协同程序提供了基础和 API 协同程序(专门的生成器函数)是 Python 中异步 IO 的核心，稍后我们将深入讨论它们。 准备工作 工作环境 在本文中，我使用术语 async IO 来表示异步 IO 的语言无关设计，而 asyncio 指的是 Python 包。 你需要 Python 3.7或者更高版本来完整地阅读本文，还需要 aiohttp 和 aiofiles 包1234&gt;$ python3.7 -m venv ./py37async&gt;$ source ./py37async/bin/activate#Windows:.\py37async\Scripts\activate.bat&gt;$ pip install --upgrade pip aiohttp aiofiles # Optional: aiodns&gt; 在Async IO前世今生Async IO用在什么地方?Async IO 比起多进程和线程, 知名度会更低一点, 来一点一点了解。 Parallelism(并行性): 在同一时间执行多个操作。Multiprocessing(多进程): 是一种实现Parallelism(并行性)的手段, 它需要在计算机的中央处理单元(cpu 或内核)上分配任务。 多进程非常适合处理CPU密集型(CPU-bound)的任务: 非常依赖循环或者数学计算通常属于这一类。Concurrency(并发性)是一个比并行性稍宽泛的术语。 它表明多个任务能够以重叠的方式运行。 (有一种说法是，并发并不意味着并行。) 线程是一种并发执行模型，多个线程轮流执行任务。 一个进程可以包含多个线程。 因为全局解释器锁(GIL)的关系，Python 与线程的关系非常复杂，但这超出了本文的范围。 了解线程处理的重要性在于，它更适合处理IO密集型(IO-bound)相关的任务。 当计算机内核工作从开始到结束时，主要的消耗都在输入 / 输出上面。 总结一下，Concurrency(并发性)包括Multiprocessing(多进程)(适合处理CPU密集型的任务)和threading(线程)(适合处理IO密集型的任务)。 Multiprocessing(多进程)是Parallelism(并行性)的一种形式，Parallelism(并行性)是Concurrency(并发性)的一种特定类型(子集)。 Python multiprocessing、threading 和 concurrent.futures包 为这两者提供了长期的支持。 现在是时候加入一个新成员了。 在过去的几年中，一个分离的设计已经更加全面地内置到 CPython 中: asynchronous IO(异步 IO)，通过标准库的 asyncio 包和新的 async 和 await 关键字启用。需要澄清的是，asynchronous IO 并不是一个新发明的概念，它已经存在或者正在被构建到其他语言和运行时环境中，比如 Go、 C# 或者 Scala。 Python 文档将 asyncio 包称为编写并发代码的库。 但是，异步 IO 不是线程，也不是多进程。 它不是建立在这两者之上的。 实际上，async IO 是一种单线程、单进程的设计: 它使用cooperative multitasking(协作多任务)，本笔记结束时你将充实这个术语。 换句话说，尽管在单个进程中使用单个线程，async IO 可以给人一种并发的感觉。 协同程序(async IO 的一个主要特性)可以并发调度，但它们本身并不是并发的。 重申一下，async IO 是并发编程的一种风格，但它不是Parallelism。 与Multiprocessing相比，它更接近于threading，但与这两者非常不同，是并发技巧中的一个独立成员。 还剩下一个问题, asynchronous是什么意思? 要注意下面asynchronous(异步)的介绍并不是一个严格的定义, 但是我们可以如此描述: Asynchronous routines(异步例程)可以在等待最终结果时“暂停” ，同时让其他routines运行 通过上述机制，异步代码促进了并发执行。 换句话说，异步代码给出了并发的外观和感觉 这里有一个图表把它们放在一起。 白色术语代表概念，绿色术语代表实施或生效的方式 ok, 对于并发编程模型之间的比较先停止。 这个笔记主要关注async IO的子组件、如何使用它以及围绕它涌现的 api。 要彻底探索threading与multiprocessing相对于async IO的区别，请查看 Jim Anderson 对 Python 中并发性的概述: overview of concurrency in Python async IO 解释 异步输入输出一开始看起来似乎是违反直觉和矛盾的。 搞并发代码的东西如何使用一个线程和一个 CPU 核心？ 下面这个例子很好地解释了一切: 陈刀仔之徒卢本伟举办了一场斗地主争霸赛，在这场比赛中，他将与多名水友打牌, 并夺得胜利。 他有两种比赛的方式: 同步和异步。 假设: 24个对手 卢本伟在5秒内打出1次牌 每局游戏平均每人要打出30次牌(总共一局60次) Synchronous version(同步版本): 卢本伟1次玩1局斗地主，永远不要同时玩两个，直到游戏结束。 每场比赛需时(55 + 5) * 30==1800秒，或者说30分钟。 整个比赛历时24 * 30==720分钟，也就是12小时。 Asynchronous version(异步版本): 卢本伟从一张比赛桌移动到另一张比赛桌，每个桌子移动一次。 当他离开桌子的时候，让水友在等待期间采取下一步行动。 24场比赛中每遍历一次需要卢本伟24 * 5==120秒，或2分钟。 整场斗地主争霸赛现在缩短到120 * 30==3600秒，或者只有1个小时。 只有一位卢本伟，他只有一双手，一次只能移动打一次牌。 但是在赛场不停地切换比赛座, 让时间从12小时减少到了1小时。 因此， cooperative multitasking(协同多任务)是一种fancy的说法，即程序的事件循环(稍后再详述)与多个任务通信，让每个任务在最佳时间轮流运行。 Async IO 需要很长的等待时间，否则函数会被阻塞，并允许其他函数在停机期间运行。 (阻塞函数有效地阻止其他函数从启动到返回的时间内运行。) asyncio 模块 和 async/await现在您已经了解了async IO 设计的一些背景知识，接下来让我们探索 Python 的实现。 Python 的 asyncio 包(在 Python 3.4中引入)及其两个关键字 async 和 await 可以达到不同的目的，但是它们一起可以帮助您声明、构建、执行和管理异步代码。 关于 async/await 的语法 和 Native Coroutines(本地协程) A Word of Caution: 小心你在网上读到的东西。 async IO API 已经从 Python 3.4迅速发展到 Python 3.7。 一些旧的模式已经不再使用，一些最初被禁止的东西现在可以通过新的引入来使用。 本笔记也将很快加入过时的垃圾桶。 - 2020-1-6 17:52:02 async IO 的核心是 coroutines (协同程序)。 coroutines 是 Python 生成器函数的特殊版本。 让我们从一个 baseline(基础版本)定义开始，然后在这里进行构建: 协同程序是一个函数，它可以在到达 return 之前暂停执行，并且可以间接地将控制权传递给另一个 coroutine 一段时间。 稍后，你将更深入地了解传统生成器到底是如何重新用于协同程序的。 目前，了解协同程序如何工作的最简单方法是开始制作一些协同程序。 asyncio API下面介绍 asyncio 模块最主要的几个API。注意，必须使用 Python 3.7 或更高版本，早期的语法已经变了。 第一步，import 加载 asyncio 模块。 1import asyncio 第二步，函数前面加上 async 关键字，就变成了 async 函数。这种函数最大特点是执行可以暂停，交出执行权。 12&gt; async def main():&gt; 第三步，在 async 函数内部的异步任务前面，加上await命令。 12&gt; await asyncio.sleep(1)&gt; 上面代码中，asyncio.sleep(1) 方法可以生成一个异步任务，休眠1秒钟然后结束。 执行引擎遇到await命令，就会在异步任务开始执行之后，暂停当前 async 函数的执行，把执行权交给其他任务。等到异步任务结束，再把执行权交回 async 函数，继续往下执行。 第四步，async.run() 方法加载 async 函数，启动事件循环。 12&gt; asyncio.run(main())&gt; 上面代码中，asyncio.run() 在事件循环上监听 async 函数main的执行。等到 main 执行完了，事件循环才会终止。 asyncio 模块在单线程上启动一个事件循环（event loop），时刻监听新进入循环的事件，加以处理，并不断重复这个过程，直到异步任务结束。事件循环的内部机制，可以参考 JavaScript 的模型，两者是一样的。 async 函数示例 让我们采用浸入式方法编写一些异步 IO 代码。 这个简短的程序是 async IO 的 Hello World，但是在说明其核心功能方面还有很长的路要走: 12345678910111213141516171819#!/usr/bin/env python3# count_async.pyimport asyncioasync def count(): print("One") await asyncio.sleep(1) print("Two")async def main(): await asyncio.gather(count(), count(), count())if __name__ == "__main__": import time s = time.perf_counter() asyncio.run(main()) elapsed = time.perf_counter() - s print(f"&#123;__file__&#125; executed in &#123;elapsed:0.2f&#125; seconds.") 上面脚本中，在 async 函数main的里面，asyncio.gather() 方法将多个异步任务（三个 count()）包装成一个新的异步任务，必须等到内部的多个异步任务都执行结束，这个新的异步任务才会结束。 脚本的运行结果如下。 12345678$ python3 count_async.pyOneOneOneTwoTwoTwocount_async.py executed in 1.01 seconds. 上面运行结果的原因是，三个 count() 依次执行，打印完 One，就休眠1秒钟，把执行权交给下一个 count()，所以先连续打印出三个 One。等到1秒钟休眠结束，执行权重新交回第一个 count()，开始执行 await 命令下一行的语句，所以会接着打印出三个Two。脚本总的运行时间是1秒。 这个输出的顺序是异步 IO 的核心。 对 count ()的每个调用进行通信是单个事件循环或协调器。 当每个任务到达并等待 asyncio.sleep (1)时，该函数对事件循环大喊，并将控制权交还给它，它说: “我要睡一秒钟。 在此期间，继续做一些有意义的事情。” 作为对比，下面是这个例子的同步版本 synchronous.py。 12345678910111213141516171819#!/usr/bin/env python3# count_synchronous.pyimport timedef count(): print("One") time.sleep(1) print("Two")def main(): for _ in range(3): count()if __name__ == "__main__": s = time.perf_counter() main() elapsed = time.perf_counter() - s print(f"&#123;__file__&#125; executed in &#123;elapsed:0.2f&#125; seconds.") 执行时，顺序和执行时间会有一个细微但关键的变化: 12345678$ python3 count_synchronous.pyOneTwoOneTwoOneTwocount_synchronous.py executed in 3.01 seconds. 虽然使用 time.sleep ()和 asyncio.sleep ()可能看起来很老套，但它们被用作任何涉及等待时间的时间密集型进程的替代品。 (你可以等待的最平凡的事情就是一个基本上什么都不做的睡眠调用。) 也就是说，time.sleep ()可以表示任何耗时的阻塞函数调用，而 asyncio.sleep ()用于代替非阻塞调用(但也需要一些时间才能完成)。 正如你将在下一节中看到的，等待包括 asyncio.sleep ()在内的内容的好处是，周围的函数可以暂时将控制权交给另一个更容易立即执行某些操作的函数。 相比之下，time.sleep ()或任何其他阻塞调用都与异步 Python 代码不兼容，因为它会在休眠期间停止一切。 Async IO的规则在这里, 一个关于 async, await, 和coroutine functions 的更加正式的定义是它们在创建的时候是有序的 语法 async def 引入了一个 native coroutine(本地协程) 或者说一个 asynchronous generator(异步生成器) , 而表达式 async with 和 async for 也是合法的, 稍后你会看到它们 关键字 await 将函数控制传递回 event loop(事件循环)。 (它暂停执行周围的协同程序。) 如果 Python 遇到 g ()范围内的 await f ()表达式，这就是 await 告诉事件循环，“暂停 g ()的执行，直到返回我正在等待的 f ()的结果。 与此同时，让其它部分依旧运行。” 在代码中，第二个要点看起来大致如下: 1234async def g(): # Pause here and come back to g() when f() is ready r = await f() return r 对于何时以及如何使用 async / await，还有一套严格的规则。 无论你是否还在学习语法，或者已经接触过使用 async / await，这些方法都很方便: 使用 async def 引入的函数是 coroutine。 它可以使用await, return, 或者 yield，但所有这些都是可选的。 声明 async def noop () : pass 是合法的: 使用 await and/or return 创建一个 coroutine 函数。 要调用协同程序函数，必须 await 它去获取它的结果。 在 async def 块中使用 yield 不太常见(而且最近在 Python 中才是合法的)。 这将创建一个异步生成器，您可以使用 async for 对其进行迭代。 暂时忘记异步生成器，专注于认真对待 coroutine 函数的语法，这些函数使用 await and/or return。 任何使用 async def 定义的内容都不能使用 yield from，这将引发 SyntaxError 错误。 就像在 def 函数之外使用 yield 是 SyntaxError 一样，在 async def coroutine 之外使用 await 也是 SyntaxError 。 你只能在协同程序的主体(body)中使用 await 。 以下是一些简短的例子，旨在总结上述几条规则: 12345678910111213async def f(x): y = await z(x) # OK - `await` and `return` allowed in coroutines return yasync def g(x): yield x # OK - this is an async generatorasync def m(x): yield from gen(x) # No - SyntaxErrordef m(x): y = await z(x) # Still no - SyntaxError (no `async def` here) return y 最后, 当你使用 await f()的时候, f()必须是一个 awaitable 的对象.啥? 这没什么卵用?现在你只需知道一个awaitable的对象必须是(1)另一个coroutine, 或者是(2)一个定义了 .__await__()dunder方法而且返回一个迭代器的对象。如果您正在编写一个程序，对于大多数目的来说，您只需要担心(1)类情况。 这又给我们带来了另一个技术上的区别，您可能会看到它的弹出: 将函数标记为 coroutine 的一种较老的方法是使用@asyncio 来装饰一个普通的 def 函数。 协同作用。 结果是一个基于生成器的协同程序( generator-based coroutine )。 由于在 Python 3.5中使用了 async / await 语法，这种结构已经过时。 这两个 协程 基本上是等价的(两者都是 awaitable ) ，但第一个协程是基于生成器的( generator-based )，而第二个协程是本地协同程序(native coroutine): 12345678910import asyncio@asyncio.coroutinedef py34_coro(): """Generator-based coroutine, older syntax""" yield from stuff()async def py35_coro(): """Native coroutine, modern syntax""" await stuff() 如果您自己编写任何代码，为了显式而不是隐式( explicit rather than implicit )，请选择 native coroutines。 基于生成器的协程将在 Python 3.10中删除( removed)。 在本笔记的后半部分，我们将仅仅为了解释而涉及一点点基于生成器的协程。 之所以引入 async / await，是为了使协同程序成为 Python 的一个独立特性，可以轻松地将其与普通的生成器函数区分开来，从而减少模糊性。 不要陷入基于生成器的协同程序，这些协同程序已经被 async / await 故意过时( deliberately outdated )了。 它们有自己的小规则集(例如，await 不能用于基于生成器的协同程序) ，如果坚持使用 async / await 语法，那么这些规则在很大程度上是不相关的。 我们来看一些更复杂的栗子。 这里有一个关于 async IO 如何减少等待时间的栗子: 给定一个 coroutine, 维持(maintain)一个持续产生在range[0, 10]之间随机整数的 makerandom() 函数, 直到其中一个超过阈值(threshold)为止 。 你希望让这个 coroutine 的多个调用不需要相互等待连续地完成。 您可以基本上遵循上面两个脚本中的模式，只需稍作修改: 123456789101112131415161718192021222324252627282930313233#!/usr/bin/env python3# rand.pyimport asyncioimport random# ANSI colorsc = ( "\033[0m", # End of color "\033[36m", # Cyan "\033[91m", # Red "\033[35m", # Magenta)async def makerandom(idx: int, threshold: int = 6) -&gt; int: print(c[idx + 1] + f"Initiated makerandom(&#123;idx&#125;).") i = random.randint(0, 10) while i &lt;= threshold: print(c[idx + 1] + f"makerandom(&#123;idx&#125;) == &#123;i&#125; too low; retrying.") await asyncio.sleep(idx + 1) i = random.randint(0, 10) print(c[idx + 1] + f"---&gt; Finished: makerandom(&#123;idx&#125;) == &#123;i&#125;" + c[0]) return iasync def main(): res = await asyncio.gather(*(makerandom(i, 10 - i - 1) for i in range(3))) return resif __name__ == "__main__": random.seed(444) r1, r2, r3 = asyncio.run(main()) print() print(f"r1: &#123;r1&#125;, r2: &#123;r2&#125;, r3: &#123;r3&#125;") 彩色输出比我能说的要多得多，并且让你了解这个脚本是如何执行的: 这个程序使用一个main coroutine，makerandom () ，并且在3个不同的输入端并发地运行它。 大多数程序将包含小的、模块化的协程和一个将每个较小的协程整合在一起的 wrapper函数。 然后使用 main ()通过在一些迭代器或池(pool)之间映射到central coroutine来收集任务(futures)。 在这个小栗子中，池(pool)是range (3)。 在后面提供的一个更完整的示例中，它是一组需要被请求、解析和并发处理的 URL，而main ()封装了每个 URL 的整个例程(routine)。 虽然“生成随机整数”(比其他任何方法都要 CPU-bound )可能不是 asyncio 的最佳选择，但是在这个示例中，asyncio.sleep ()的出现是为了模拟 IO-bound 的进程，其中涉及不确定的等待时间。 例如，asyncio.sleep ()调用可能表示在消息应用程序中的两个客户机之间发送和接收非随机整数。 Async IO 设计模式 Async IO 提供了自己的一组可能的脚本设计，本节将介绍这些设计。 Chaining Coroutines协程的一个关键特性是它们可以链接在一起。 (记住，一个协同程序对象是可以被唤醒的( awaitable )，所以另一个协同程序可以等待 (await) 它。) 这样你就可以把程序分解成更小的、可管理的、可回收的协同程序: 1234567891011121314151617181920212223242526272829303132333435363738394041#!/usr/bin/env python3# chained.pyimport asyncioimport randomimport timeasync def part1(n: int) -&gt; str: i = random.randint(0, 10) print(f"part1(&#123;n&#125;) sleeping for &#123;i&#125; seconds.") await asyncio.sleep(i) result = f"result&#123;n&#125;-1" print(f"Returning part1(&#123;n&#125;) == &#123;result&#125;.") return resultasync def part2(n: int, arg: str) -&gt; str: i = random.randint(0, 10) print(f"part2&#123;n, arg&#125; sleeping for &#123;i&#125; seconds.") await asyncio.sleep(i) result = f"result&#123;n&#125;-2 derived from &#123;arg&#125;" print(f"Returning part2&#123;n, arg&#125; == &#123;result&#125;.") return resultasync def chain(n: int) -&gt; None: start = time.perf_counter() p1 = await part1(n) p2 = await part2(n, p1) end = time.perf_counter() - start print(f"--&gt;Chained result&#123;n&#125; =&gt; &#123;p2&#125; (took &#123;end:0.2f&#125; seconds).")async def main(*args): await asyncio.gather(*(chain(n) for n in args))if __name__ == "__main__": import sys random.seed(444) args = [1, 2, 3] if len(sys.argv) == 1 else map(int, sys.argv[1:]) start = time.perf_counter() asyncio.run(main(*args)) end = time.perf_counter() - start print(f"Program finished in &#123;end:0.2f&#125; seconds.") 请仔细关注输出，其中 part1() 睡眠时间可变， part2() 开始处理可用的结果: 1234567891011121314151617$ python3 chained.py 9 6 3part1(9) sleeping for 4 seconds.part1(6) sleeping for 4 seconds.part1(3) sleeping for 0 seconds.Returning part1(3) == result3-1.part2(3, 'result3-1') sleeping for 4 seconds.Returning part1(9) == result9-1.part2(9, 'result9-1') sleeping for 7 seconds.Returning part1(6) == result6-1.part2(6, 'result6-1') sleeping for 4 seconds.Returning part2(3, 'result3-1') == result3-2 derived from result3-1.--&gt;Chained result3 =&gt; result3-2 derived from result3-1 (took 4.00 seconds).Returning part2(6, 'result6-1') == result6-2 derived from result6-1.--&gt;Chained result6 =&gt; result6-2 derived from result6-1 (took 8.01 seconds).Returning part2(9, 'result9-1') == result9-2 derived from result9-1.--&gt;Chained result9 =&gt; result9-2 derived from result9-1 (took 11.01 seconds).Program finished in 11.01 seconds. 在这种设置中，main()的运行时间等于它收集并调度的任务的最大运行时间 References Async IO in Python: A Complete Walkthrough Overview of Concurrency in Python]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ArrayList Excecises]]></title>
    <url>%2F2020%2F01%2F04%2Farray-excecises%2F</url>
    <content type="text"><![CDATA[Ex1: 扫雷游戏我们来写一个小程序： 程序接收三个参数，M，N和p，然后生成一个M * N的矩阵，然后每一个cell(小格子)有p的概率是地雷。生成矩阵后，再计算出每一个cell周围地雷的数量。 代码实现 1234567891011121314151617181920212223242526272829303132333435363738import random# 定义生成棋盘函数def sweeper(m, n, p): # tips: 生成m+2&amp;n+2的初始棋盘来避免边界判断, -1代表雷 board = [[None] * (n + 2) for i in range(m + 2)] for i in range(1, m + 1): for j in range(1, n + 1): r = random.random() board[i][j] = -1 if r &lt; p else 0 # 绘制棋盘 for i in range(1, m + 1): for j in range(1, n + 1): print("*", end=" ") if board[i][j] == -1 else print(".", end=" ") print() # 计算每个格子的值 for i in range(1, m + 1): for j in range(1, n + 1): if (board[i][j] != -1): # 计算四周的地雷数量 for ii in range(i - 1, i + 2): for jj in range(j - 1, j + 2): if (board[ii][jj] == -1): board[i][j] += 1 print() # 打印结果 for i in range(1, m + 1): for j in range(1, n + 1): print("*", end=" ") if board[i][j] == -1 else print(board[i][j], end=" ") print()# 生成10x10, 概率p=0.2的扫雷棋盘sweeper(10, 10, 0.2) 展示效果: 12345678910111213141516171819202122&gt;. . . . . . . . . . &gt;. . . . * * . . . * &gt;. . . . . * * * * . &gt;. . . . . . * . * . &gt;. . . . . . . . . . &gt;. . . . . . . . . * &gt;. * . . * . * . . . &gt;. . . . * . . . . . &gt;. * . * . * . . . * &gt;* . . . . * . * . . &gt;&gt;0 0 0 1 2 2 1 0 1 1 &gt;0 0 0 1 * * 4 3 3 * &gt;0 0 0 1 3 * * * * 3 &gt;0 0 0 0 1 3 * 5 * 2 &gt;0 0 0 0 0 1 1 2 2 2 &gt;1 1 1 1 1 2 1 1 1 * &gt;1 * 1 2 * 3 * 1 1 1 &gt;2 2 3 3 * 4 2 1 1 1 &gt;2 * 2 * 4 * 3 1 2 * &gt;* 2 2 1 3 * 3 * 2 1 &gt; tips: 第7行代码是精髓, 有很多时候可以通过简单的方法来避免繁琐的边界判断过程 Ex2: 矩阵0变换给一个m×n的矩阵，如果有一个元素为0，则把该元素对应的行与列所有元素全部变成0。 12345matrix = [ [ 1, 1, 1, 1, 1, 0, 1, 1, 1, 1 ], [ 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ], [ 1, 1, 0, 1, 1, 1, 1, 1, 1, 1 ], [ 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ], [ 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ] ] 也就是变成这样 ↓ 12345matrix =[ [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 0, 1, 1, 1, 1], [1, 1, 0, 1, 1, 0, 1, 1, 1, 1] ] 思路1: 先想第一种, 我再去创建一个 m×n 的 数组(matrix), 然后这个数组里面专门存0的位置, 就是把0的位置设置为True; 这种方法需要用到额外mxn的空间→空间复杂度O(m×n) 思路2: 用set, 一个放行, 一个放列; 当然可以, 不过这个题先用列表来做 思路3: 我们是否需要维持(maintain)一个 m×n 的数组? 是可以不需要的; 只需要两个一维数组就够了, 一个maintain哪些列有0, 另一个maintain哪些行有0; 这种方法的空间复杂度为O(m+n) →space complexity 1234567891011121314def zero(matrix): m = [None] * len(matrix) # 行 n = [None] * len(matrix[0]) # 列 for i in range(len(matrix)): # 遍历行 for j in range(len(matrix[0])): # 遍历列 if (matrix[i][j] == 0): # 如果出现了0了 m[i] = 1 # 就把这一行设为1 n[j] = 1 # 就把这一列设为1 # 通过m和n两个一位数组, 修改原有矩阵(matrix) for i in range(len(matrix)): for j in range(len(matrix[0])): if (m[i] == 1 or n[j] == 1): matrix[i][j] = 0 12345matrix = [ [ 1, 1, 1, 1, 1, 0, 1, 1, 1, 1 ], [ 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ], [ 1, 1, 0, 1, 1, 1, 1, 1, 1, 1 ], [ 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ], [ 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ] ] 123# 原有matrixfor x in matrix: print(x, sep=" ") 1234567&gt;# 输出&gt;[1, 1, 1, 1, 1, 0, 1, 1, 1, 1]&gt;[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]&gt;[1, 1, 0, 1, 1, 1, 1, 1, 1, 1]&gt;[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]&gt;[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]&gt; ↓↓↓ 1234# 修改后matrixzero(matrix)for x in matrix: print(x, sep=" ") 1234567&gt;# 输出&gt;[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]&gt;[1, 1, 0, 1, 1, 0, 1, 1, 1, 1]&gt;[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]&gt;[1, 1, 0, 1, 1, 0, 1, 1, 1, 1]&gt;[1, 1, 0, 1, 1, 0, 1, 1, 1, 1]&gt; Ex3: 九宫图 123456789101112131415161718192021def magic_square(n): magic = [[0] * (n) for i in range(n)] row = n - 1 col = n//2 magic[row][col] = 1 for i in range(2, n * n + 1): try_row = (row + 1) % n try_col = (col + 1) % n if (magic[try_row][try_col] == 0): row = try_row col = try_col else: # row往上移1行, 有可能会产生负数, 所以+n row = (row - 1 + n) % n magic[row][col] = i for x in magic: print(x, sep=" ") 1magic_square(3) 12345&gt;# 输出&gt;[4, 9, 2]&gt;[3, 5, 7]&gt;[8, 1, 6]&gt; 1magic_square(5) 1234567&gt;# 输出&gt;[11, 18, 25, 2, 9]&gt;[10, 12, 19, 21, 3]&gt;[4, 6, 13, 20, 22]&gt;[23, 5, 7, 14, 16]&gt;[17, 24, 1, 8, 15]&gt;]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>interview</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[find the missing number]]></title>
    <url>%2F2020%2F01%2F04%2Ffind-the-missing-number%2F</url>
    <content type="text"><![CDATA[Question: 找到丢失的数字现在你手上有n-1个数字, 这些数字的范围是[1, n]且这n-1个数字中没有重复的数字.由上述条件可知: 你手上的数字丢失了一个.请编写一段高效的找到该确实数字的代码. 考察需求 ​ 首先你应该要对面试官问的这道题的需求, 在这里就是这个数字列表是有序的还是无序的? 那么你问了面试官之后呢, 面试就告诉你了, 这就是一个良好的开始. 考察思路: 首先需要问清楚题目意思 这个数字列表是有序的还是无序的? 考虑各种方法的时间复杂度, 空间复杂度 算法的思路 第一步应该怎么做 第二步应该怎么做 程序实现 能不能写出一些测试用例, test_case, 用我们写好的程序跑过去? 实现思路(5种)第1种: 先排序, 再用二分法 使用二分法 这就涉及到我们的List是有序的还是无序的? 先排序, 再用二分法 这就涉及到各种排序算法的优劣性 List.sort()或者sorted(List) 第2种: 先排序, 再用线性的查找方式 也就是for循环呗, 每次看这个 i 等不等于上一个 i+1 不等于的话就把当前的 i 打印出来 第3种: 先求和(速度非常快) 首先我们是缺少了一个数字对不对? 我们可以把这些数字加起来, 求和, 记为 sum_now 然后如果我们 1~n 的数字都存在的话, 原本的1到n的累加和我们是不是已经知道了 也就是 (1+n) * n / 2 (首相+末项) × 项数 ÷ 2 记为 sum_all 那么 sum_all - sum_now 就能得出我们缺失的那个数字 第4种: 计数排序 可以理解为现在我们有 n 个抽屉, 编号 1~n 号 然后我们遇到一个数字, 就把这个数字放到抽屉里面去 这个是5我们放到第5个抽屉 这个是8我们放到第8个抽屉 当所有数过完一遍后, 我们看那个抽屉是空的, 我们是不是就知道哪个数缺失了 第5种: XOR 异或(速度是最快的, 异或操作比加减乘除都要快, 因为计算机是要做加减乘除的时候要先转换成二进制再进行计算, 所以直接在二进制层面上的异或操作是最快的) 0^1 = 1 0^0 = 0 1^0 = 1 1^1 = 0 A^A = 0 A^0 = A a⊕b = (¬a ∧ b) ∨ (a ∧¬b) 如果a、b两个值不相同，则异或结果为1。如果a、b两个值相同，异或结果为0。 支持交换律 A^B^C = C^B^A = … 计算机中数的运算转换成二进制进行的, 比如说我们的 3 转换成二进制就是 0011, 8 转换成二进制就是 1000 做法: 我们先拿 1异或2一直异或到n 1^2^3^4^…^n 再和我们的乱序List的异或作比较 a0 ^ a1 ^ a2 ^ …^ 0 ^ … ^ an-2 1,2,3,…异或下面的都得到0, 只剩 x 异或下面的 0(因为那个数已经缺失了, 所以是0), 得到 x 那么这个 x 就是我们丢失的数字 tips: 98765 * 32 等同于 98765 * 2^5 等同于在二进制上左移5位-&gt; 位操作 198765&lt;&lt;5 是一样的]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[数据结构与算法(Python)]]></title>
    <url>%2F2019%2F08%2F16%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95(Python)%2F</url>
    <content type="text"><![CDATA[Info从头开始用Python实现基础数据结构与算法, 在Gitbook更新学习笔记, Mark一下~]]></content>
      <categories>
        <category>DataStructure</category>
        <category>Algorithm</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python中yield的用法详解[转载]]]></title>
    <url>%2F2019%2F08%2F16%2Fyield_in_python%2F</url>
    <content type="text"><![CDATA[原文作者吐槽: 首先我要吐槽一下，看程序的过程中遇见了yield这个关键字，然后百度的时候，发现没有一个能简单的让我懂的，讲起来真TM的都是头头是道，什么参数，什么传递的，还口口声声说自己的教程是最简单的，最浅显易懂的，我就想问没有有考虑过读者的感受。 接下来是正题： 首先，如果你还没有对yield有个初步分认识，那么你先把yield看做“return”，这个是直观的，它首先是个return，普通的return是什么意思，就是在程序中返回某个值，返回之后程序就不再往下运行了。看做return之后再把它看做一个是生成器（generator）的一部分（带yield的函数才是真正的迭代器），好了，如果你对这些不明白的话，那先把yield看做return,然后直接看下面的程序，你就会明白yield的全部意思了： 123456789def foo(): print("starting...") while True: res = yield 4 print("res:",res)g = foo()print(next(g))print("*"*20)print(next(g)) 就这么简单的几行代码就让你明白什么是yield，代码的输出这个： 12345starting...4********************res: None4 我直接解释代码运行顺序，相当于代码单步调试：1.程序开始执行以后，因为foo函数中有yield关键字，所以foo函数并不会真的执行，而是先得到一个生成器g(相当于一个对象)2.直到调用next方法，foo函数正式开始执行，先执行foo函数中的print方法，然后进入while循环3.程序遇到yield关键字，然后把yield想想成return,return了一个4之后，程序停止，并没有执行赋值给res操作，此时next(g)语句执行完成，所以输出的前两行（第一个是while上面的print的结果,第二个是return出的结果）是执行print(next(g))的结果，4.程序执行print(““20)，输出20个*5.又开始执行下面的print(next(g)),这个时候和上面那个差不多，不过不同的是，这个时候是从刚才那个next程序停止的地方开始执行的，也就是要执行res的赋值操作，这时候要注意，这个时候赋值操作的右边是没有值的（因为刚才那个是return出去了，并没有给赋值操作的左边传参数），所以这个时候res赋值是None,所以接着下面的输出就是res:None,6.程序会继续在while里执行，又一次碰到yield,这个时候同样return 出4，然后程序停止，print函数输出的4就是这次return出的4. 到这里你可能就明白yield和return的关系和区别了，带yield的函数是一个生成器，而不是一个函数了，这个生成器有一个函数就是next函数，next就相当于“下一步”生成哪个数，这一次的next开始的地方是接着上一次的next停止的地方执行的，所以调用next的时候，生成器并不会从foo函数的开始执行，只是接着上一步停止的地方开始，然后遇到yield后，return出要生成的数，此步就结束。**** 123456789def foo(): print("starting...") while True: res = yield 4 print("res:",res)g = foo()print(next(g))print("*"*20)print(g.send(7)) 再看一个这个生成器的send函数的例子，这个例子就把上面那个例子的最后一行换掉了，输出结果： 12345starting...4********************res: 74 先大致说一下send函数的概念：此时你应该注意到上面那个的紫色的字，还有上面那个res的值为什么是None，这个变成了7，到底为什么，这是因为，send是发送一个参数给res的，因为上面讲到，return的时候，并没有把4赋值给res，下次执行的时候只好继续执行赋值操作，只好赋值为None了，而如果用send的话，开始执行的时候，先接着上一次（return 4之后）执行，先把7赋值给了res,然后执行next的作用，遇见下一回的yield，return出结果后结束。 5.程序执行g.send(7)，程序会从yield关键字那一行继续向下运行，send会把7这个值赋值给res变量6.由于send方法中包含next()方法，所以程序会继续向下运行执行print方法，然后再次进入while循环7.程序执行再次遇到yield关键字，yield会返回后面的值后，程序再次暂停，直到再次调用next方法或send方法。 这就结束了，说一下，为什么用这个生成器，是因为如果用List的话，会占用更大的空间，比如说取0,1,2,3,4,5,6…………1000你可能会这样： 12for n in range(1000): a=n 这个时候range(1000)就默认生成一个含有1000个数的list了，所以很占内存。这个时候你可以用刚才的yield组合成生成器进行实现，也可以用xrange(1000)这个生成器实现yield组合： 1234567def foo(num): print(&quot;starting...&quot;) while num&lt;10: num=num+1 yield numfor n in foo(0): print(n) 输出： 1234567891011starting...12345678910 xrange(1000): 12for n in xrange(1000): a=n 其中要注意的是python3时已经没有xrange()了，在python3中，range()就是xrange()了，你可以在python3中查看range()的类型，它已经是个&lt;class ‘range’&gt;了，而不是一个list了，毕竟这个是需要优化的。 本文章遵循 CC 4.0 by-sa 版权协议，转载请附上原文出处链接和本声明。原文链接：https://blog.csdn.net/mieleizhi0522/article/details/82142856]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[kNN算法的DIY实现(仿照scikit-learn)]]></title>
    <url>%2F2019%2F08%2F15%2FDo-it-yourself-implementation-of-kNN-algorithm%2F</url>
    <content type="text"><![CDATA[什么是kNN算法?kNN算法, 又叫K最近邻算法, 可用于分类或者回归. 所谓K最近邻，就是k个最近的邻居的意思，说的是每个样本都可以用它最接近的k个邻居来代表。 其特点是: 思想极度简单 应用数学知识几乎为零 效果好 可以解释机器学习算法使用过程中的很多细节问题 更完整刻画一起学习应用的流程 分类精度高, 对缺失值不敏感 懒加载, 模型复杂度高 kNN算法执行流程 根据欧几里得距离公式求出样本点与所有点的距离, 然后按照距离升序排序, 取出前k个点, 样本点是什么类别, 那么k个点就是什么类别 kNN的实质: k个样本如果足够地相似的话, 那么他们就很有可能属于同一个类别 自己动手实现kNN算法123456789101112131415161718192021222324import numpy as npfrom math import sqrtfrom collections import Counterdef kNN_classify(k, X_train, y_train, x): assert 1 &lt;= k &lt;= X_train.shape[0], "k must be valid" assert X_train.shape[0] == y_train.shape[0], \ "the size of X_train must equal to the size of y_train" assert X_train.shape[1] == x.shape[0], \ "the feature number of x must be equal to X_train" distances = [sqrt(np.sum((x_train - x)**2)) for x_train in X_train] nearest = np.argsort(distances) topK_y = [y_train[i] for i in nearest[:k]] votes = Counter(topK_y) return votes.most_common(1)[0][0]]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Algorithm</category>
        <category>Algorithm</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>knn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[First Blog]]></title>
    <url>%2F2019%2F08%2F14%2Ffirst-blog%2F</url>
    <content type="text"><![CDATA[Start -&gt; 3W&amp;1H?你是谁? (Who)我是Yukirito, 一个兴趣使然的小朋友 为什么要做Blog? (Why)大约是3个月前, 我在尝试理解支持向量机的时候, 刷到了pluskid大神的Blog, 感到十分愉悦. Blog不像社交媒体, 输出碎片化信息. 而是类似于书籍的子集. 按所含信息量多少来举例, 书籍&gt;Blog&gt;朋友圈, 所以Blog比较好输出较为结构化的信息. By the way, 不要企图用碎片化的知识来提升自己的技术能力 这个Blog是搞什么的? (What)自己之前一直是在印象笔记上做笔记, 现在将逐步把闭门的数据选择后转移到Blog上来包括但不限于: 主业CS学习笔记 副业各种点歪了技能书的学习笔记 游戏攻略 个人心得 这个Blog是搞什么的? (What)2019-08-14 22:18:24 emmmm还没开始更就有鸽的预感…原则上来说更新间隔不大于一周. 2020-01-05 02:48:37 okkk, 没有原则, 一拖就拖了3个月 其实是当时忙着找工作, 最近稳定了就”重操旧业”]]></content>
      <categories>
        <category>MISC</category>
      </categories>
  </entry>
</search>
